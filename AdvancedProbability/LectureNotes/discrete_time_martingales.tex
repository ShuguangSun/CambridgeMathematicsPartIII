
\chapter{Discrete Time Martingales}
\label{cha:discr-time-mart}

Let $(\Omega, \mathcal{F}, \Prob)$ be a probability space and $(E,
\xi)$ a measurable space.  Usually $E = \R, \R^{d}, \mathbb{C}$.  For
us, $E = \R$.  A sequence $X = (X_{n})_{n \geq 0}$ of random variables
taking values in $E$ is called a \textbf{stochastic process}.

A \textbf{filtration} is an increasing family $(\mathcal{F}_{n})_{n
  \geq 0}$ of sub-$\sigma$-algebras of $\mathcal{F}_{n}$, so
$\mathcal{F}_{n} \subseteq \mathcal{F}_{n+1}$.

Intuitively, $\mathcal{F}_{n}$ is the information available to us at
time $n$.  To every stochastic process $X$ we associate a filtration
called the natural filtration
\begin{equation}
  \label{eq:24}
  (\mathcal{F}^{X}_{n})_{n \geq 0}, \mathcal{F}_{n}^{X} =
  \sigma(X_{k}, k \leq n)
\end{equation}

A stochastic process $X$ is called adapted to $(\mathcal{F}_{n})_{n
  \geq 0}$ if $X_{n}$ is $\mathcal{F}_{n}$-measurable for all $n$.

A stochastic process $X$ is called integrable if $X_{n}$ is integrable
for all $n$.

\begin{defn}
  \label{defn:discrete_time_martingales:1}
  An adapted integrable process $(X_{n})_{n \geq 0}$ taking values in
  $\R$ is called a
  \begin{enumerate}
  \item \textbf{martingale} if $\E{X_{n} | \mathcal{F}_{m}} = X_{m}$
    for all $n \geq m$.
  \item \textbf{super-martingale} if $\E{X_{n} | \mathcal{F}_{m}} \leq
    X_{m}$ for all $n \geq m$.
  \item \textbf{sub-martingale} if $\E{X_{n} | \mathcal{F}_{m}} \geq
    X_{m}$ for all $n \geq m$.
  \end{enumerate}
\end{defn}

\begin{remark}
  A (sub,super)-martingale with respect to a filtration
  $\mathcal{F}_{n}$ is also a (sub, super)-martingale with respect to
  the natural filtration of $X_{n}$ (by the tower property)
\end{remark}


\begin{exmp}
  \label{defn:discrete_time_martingales:2}
  Suppose $(\xi_{i})$ are \iid random variables with $\E{\xi_{i}} = 0$.
  Set $X_{n} = \sum_{i=1}^{n} \xi_{i}$.  Then $(X_{n})$ is a martingale.
\end{exmp}

\begin{exmp}
  \label{defn:discrete_time_martingales:3}
  As above, but let $(\xi_{i})$ be \iid with $\E{\xi_{i}} = 1$. Then
  $X_{n} = \Pi_{i=1}^{n} \xi_{i}$ is a martingale.
\end{exmp}

\begin{defn}
  \label{defn:discrete_time_martingales:4}
  A random variables $T: \Omega \rightarrow \mathbb{Z}_{+} \cup \{ \infty \}$
  is called a stopping time if $\{ T \leq n \} \in \mathcal{F}_{n}$
  for all $n$.  Equivalently, $\{ T = n \} \in \mathcal{F}_{n}$ for
  all $n$.
\end{defn}

\begin{exmp}
  \label{defn:discrete_time_martingales:5}
  \begin{enumerate}
  \item Constant times are trivial stopping times.
  \item $A \in \mathcal{B}(\R)$.  Define $T_{A} = \inf \{ n \geq 0 |
    X_{n} \in A \}$, with $\inf \emptyset = \infty$.  Then $T_{A}$ is a
    stopping time.
  \end{enumerate}
\end{exmp}

\begin{proposition}
  Let $S, T, (T_{n})$ be stopping times on the filtered probability
  space $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \Prob)$.  Then $S \wedge
  T, S \vee T, \inf_{n} T_{n}, \liminf_{n} T_{n}, \limsup_{n} T_{n}$
  are stopping times. 
\end{proposition}

\begin{notation}
  $T$ stopping time, then $X_{T}(\omega) = X_{T(\omega)}(\omega)$. The
  stopped process $X^{T}$ is defined by $X^{T}_{t} = X_{T \wedge t}$.

  $\mathcal{F}_{T} = \{ A \in \mathcal{F} | A \cap {T \leq T} \in
  \mathcal{F}_{t}, \forall t \}$.
\end{notation}

\begin{proposition}
  $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \Prob)$, $X = (X_{n})_{n
    \geq 0}$ is adapted.
  \begin{enumerate}
  \item $S \leq T$, stopping times, then $\mathcal{F}_{S} \subseteq \mathcal{F}_{T}$
  \item $X_{T} \I{T < \infty}$ is $\mathcal{F}_{T}$-measurable.
  \item $T$ a stopping time, then $X^{T}$ is adapted
  \item If $X$ is integrable, then $X^{T}$ is integrable.
  \end{enumerate}
\end{proposition}

\begin{proof}
  Let $A \in \xi$.  Need to show that $\{ X_{T} \I{T < \infty} \in A
  \} \in \mathcal{F}_{T}$.
  \begin{align}
    \label{eq:25}
    \{ X_{T} \I{T < \infty} \} \cap \{ T \leq t \} = \cup_{s \leq t}
    \left( \underbrace{\{ T = s \}}_{\mathcal{F}_{s} \subseteq
        \mathcal{F}_{t}} \cap \underbrace{\{ X_{s} \in A \}}_{\in
        \mathcal{F}_{s} \subseteq \mathcal{F}_{t}} \right) \in \mathcal{F}_{t}
  \end{align}
\end{proof}


\section{Optional Stopping}
\label{sec:optional-stopping}

\begin{thm}
  \label{defn:discrete_time_martingales:6}
  Let $X$ be a martingale.
  \begin{enumerate}
  \item \label{item:1} If $T$ is a stopping time, then $X^{T}$ is also a martingale.
    In particular, $\E{X_{T \wedge t}} = \E{X_{0}}$ for all $t$.
  \item \label{item:2}
  \item \label{item:3}
  \item \label{item:4}
  \end{enumerate}
\end{thm}

\begin{proof}
  By the tower property, it is sufficient to check
  \begin{align*}
    \label{eq:26}
    \E{X_{T \wedge t} | \mathcal{F}_{t - 1}} &= 
    \E{\sum_{i=1}^{t-1} X_{s} \underbrace{\I{T=s}}_{\in
        \mathcal{F}_{s} \subseteq \mathcal{F}_{t-1}}  |
      \mathcal{F}_{t-1}} + \E{X_{t} \I{T > t -1} | \mathcal{F}_{t-1}}
    \\
    &= \sum_{s=0}^{t-1} \I{T=s} X_{s} + \I{t>t-1}X_{t-1} = X_{T \wedge (t-1)}
  \end{align*}  Since it is a martingale, $\E{X_{T \wedge t}} = \E{X_{0}}$.
\end{proof}

\begin{thm}
  \label{defn:discrete_time_martingales:7}
  Let $X$ be a martingale.
  \begin{enumerate}
  \item If $T$ is a stopping time, then $X^{T}$ is also a martingale,
    so in particular
    \begin{equation}
      \label{eq:27}
      \E{X_{T \wedge t}} = \E{X_{0}}
    \end{equation}
  \item If $X \leq T$ are bounded stopping times, then $\E{X_{T}|
      \mathcal{F}_{S}} = X_{S}$ almost surely.
  \end{enumerate}
\end{thm}

\begin{proof}
  Let $S \leq T \leq n$.  Then $X_{T} = (X_{T} - X_{T-1}) + (X_{T-1} -
  X_{T-2}) + \dots + (X_{S+1} - X_{S}) + X_{S} = X_{s} +
  \sum_{k=0}^{n} (X_{k+1} - X_{k}) \I{S \leq k < T}$.

  Let $A \in \mathcal{F}_{s}$.  Then
  \begin{align}
    \label{eq:28}
    \E{X_{T}\I{A}} &= \E{X_{s}\I{A}} + \sum_{k=0}^{n} \E{(X_{k+1} -
      X_{k})\I{S \leq k < T} \I{A}} \\
    &= \E{X_{s} \I{A}}
  \end{align}
\end{proof}

\begin{remark}
  The optimal stopping theorem also holds for {super/sub}-martingales
  with the respective martingale inequalities in the statement.
\end{remark}

\begin{exmp}
  \label{defn:discrete_time_martingales:8}
  Suppose that $(\xi_{i})_{i}$ are random variables with
  \begin{equation}
    \label{eq:29}
    \Prob{\xi_{i} = 1} = \Prob{\xi_{i} = -1} = \frac{1}{2}
  \end{equation}  Set $X_{0} = 0, X_{n} = \sum_{i=1}^{n} \xi_{i}$.
  This is a simply symmetric random walk on $X_{n}$.

  Let $T = \inf \{ n \geq 0 : X_{n} = 1 \}$.  Then $\P{T < \infty} =
  1$, but $T$ is not bounded.
\end{exmp}

\begin{proposition}
  If $X$ is a positive supermartingale and $T$ is a stopping time
  which is finite almost surely ($\Prob{T < \infty} = 1$), then
  \begin{equation}
    \label{eq:30}
    \E{X_{T}} \leq \E{X_{0}}
  \end{equation}
\end{proposition}

\begin{proof}
  \begin{align}
    \label{eq:31}
    \E{X_{T}} = \E{\liminf_{t \rightarrow \infty} X_{t \wedge T}} \leq
    \liminf_{t \rightarrow \infty} \E{X_{t \wedge T}} \leq \E{X_{0}}
  \end{align}
\end{proof}

\section{Hitting Probabilities for a Simple Symmetric Random Walk}
\label{sec:hitt-prob-simple}

Let $(\xi_{i})$ be \iid $\pm 1$ equally likely. Let $X_{0} = 0, X_{n} =
\sum_{i=1}^{n} \xi_{i}$.  For all $x \in Z$ let
\begin{equation}
  \label{eq:32}
  T_{x} = \inf \{ n \geq 0 : X_{n} = x \}
\end{equation} which is a stopping time. We want to explore hitting
probabilities ($\Prob{T_{-a} < T_{b}})$ for $a, b > 0$.
If $\E{T} < \infty$, then by \ref{item:4} in Theorem
\ref{defn:discrete_time_martingales:7}, $\E{X_{T}} = \E{X_{0}} = 0$.
\begin{align}
  \label{eq:33}
  \E{X_{T}} = -a \Prob{T_{-a} < T_{b}} + b \Prob{T_{b} < T_{-a}} = 0
\end{align} and thus obtain that
\begin{equation}
  \label{eq:34}
  \Prob{T_{-a} < T_{b}} = \frac{b}{a+b}.
\end{equation}

Remains to check $\E{T} < \infty$.  We have $\Prob{\xi_{1} = 1,
  \xi_{a+b} = 1} = \frac{1}{2^{a+b}}$.

\section{Martingale Convergence Theorem}
\label{sec:mart-conv-theor}

\begin{thm}
  \label{defn:discrete_time_martingales:9}
  Let $X = (X_{n})_{n \geq 0}$ be a (super-)-martingale bounded in
  $L^{1}$, that is, $\sup_{n \geq 0} \E{|X_{n}|} < \infty$.  Then
  $X_{n}$ converges as $n \rightarrow \infty$ almost surely towards an
  a.s. finite limit $X \in L^{1}(\mathcal{F}_{\infty})$ with
  $\mathcal{F}_{\infty} = \sigma(\mathcal{F}_{n}, n \geq 0)$.  To
  prove it we will use Doob's trick which counts up-crossings of
  intervals with rational endpoints. 
\end{thm}

\begin{corollary}
  Let $X$ be a positive supermartingale.  Then it converges to an
  almost surely finite limit as $n \rightarrow \infty$.
\end{corollary}

\begin{proof}
  \begin{align}
    \label{eq:36}
    \E{|X_{n}|} = \E{X_{n}} \leq \E{X_{0}} < \infty
  \end{align}
\end{proof}

\begin{proof}
  Let $x = (x_{n})_{n}$ be a sequence of real numbers, and let $a < b$
  be two real numbers.  Let $T_{0}(x) = 0$ and inductively for $k \geq
  0$,
  \begin{align}
    \label{eq:37}
    S_{k+1}(x) = \inf \{ n \geq T_{k}(x): x_{n} \leq a \}
    T_{k+1}(x) = \inf \{ n \geq S_{k+1}(x): x_{n} \geq b \}
  \end{align} with the usual convention that $\inf \emptyset =
  \infty$.

  Define $N_{n}([a, b], x) = \sup \{ k \geq 0 : T_{k}(x) \leq n \}$ -
  the number of up-crossings of the interval $[a, b]$ by the sequence
  $x$ by the time $n$. As $n \rightarrow \infty$, we have
  \begin{equation}
    \label{eq:38}
    N_{n}([a,b], x) \uparrow N([a, b], x) = \sup \{ k \geq 0 :
    T_{k}(x) < \infty \}, 
  \end{equation} the total number of up-crossings of the interval $[a, b]$.
\end{proof}

\begin{lem}
  A sequence of rationals $x = (x_{n})_{n}$ converges in $\bar \R = \R
  \cup \{ \pm \infty \}$ if and only if $N([a, b], x) < \infty$ for
  all rationals $a, b$.
\end{lem}

\begin{proof}
  Assume $x$ converges.  Then if for some $a < b$ we had that
  $N([a,b], x) = \infty$, then $\liminf_{n} x_{n} \leq a < b \leq
  \limsup_{n} x_{n}$, which is a contradiction.

  Then, suppose that $x$ does converge.  Then $\liminf_{n} x_{n} >
  \limsup_{n} x_{n}$, and so taking $a, b$ rationals between these two
  numbers gives that $N([a,b], x) = \infty$ as required.
\end{proof}

\begin{thm}[Doob's up-crossing inequality]
  \label{defn:discrete_time_martingales:10}
  Let $X$ be a supermartingale and $a < b$ be two real numbers. Then
  for all $n \geq 0$,
  \begin{equation}
    \label{eq:39}
    (b-a) \E{N_{n}([a, b], X)} \leq \E{(X_{n} - a)^{-}}
  \end{equation}
\end{thm}

\begin{proof}
  For all $k$,
  \begin{equation}
    \label{eq:40}
    X_{T_{k}} - X_{S_{k}} \geq b - a
  \end{equation}
\end{proof}

\section{Uniform Integrability}
\label{sec:unif-integr}

\begin{thm}
  \label{defn:discrete_time_martingales:11}
  Suppose $X \in L^{1}$.  Then the collection of random variables
  \begin{equation}
    \label{eq:35}
    \{ \E{X | \mathcal{G}} \}
  \end{equation} for $\mathcal{G} \subseteq \mathcal{F}$ a
  sub-$\sigma$-algebra is uniformly integrable.
\end{thm}

\begin{proof}
  Since $X \in L^{1}$, for all $\epsilon > 0$ there exists $S > 0$
  such that if $A \in \mathcal{F}$ and $\Prob{A} < \delta$, then
  $\E{|X| \I{A}} \leq \epsilon$.

  Set $Y = \E{X | \mathcal{G}}$.  Then $\E{|Y|} \leq \E{|X|}$.  Choose
  $\lambda < \infty$ such that $\E{|X|} \leq \lambda \delta$.  Then
  \begin{align}
    \label{eq:41}
    \Prob{|Y| \geq \lambda} \leq \frac{\E{|Y|}}{\lambda} \leq \delta
  \end{align} by Markov's inequality.

  Then
  \begin{align}
    \label{eq:42}
    \E{|Y| \I{|Y| \geq \lambda}} \leq \E{\E{|X| | \mathcal{G}} \I{|Y|
        \geq \lambda}} \\
    &= \E{|X| \I{|Y| \geq \lambda}} \\
    &\leq \epsilon
  \end{align}
\end{proof}


\begin{defn}
  \label{defn:discrete_time_martingales:12}
  A process $X = (X_{n})_{n \geq 0}$ is called a uniformly integrable
  martingale if it is a martingale and the collection $(X_{n})$ is
  uniformly integrable.
\end{defn}

\begin{thm}
  \label{defn:discrete_time_martingales:13}
  Let $X$ be a martingale.  Then the following are equivalent.
  \begin{enumerate}
  \item \label{item:5} $X$ is a uniformly integrable martingale.
  \item \label{item:6} $X$ converges almost surely and in $L^{1}$ to a limit
    $X_{\infty}$ as $n \rightarrow \infty$.
  \item \label{item:7} There exists a random variable $Z \in L^{1}$ such that $X_{n}
    = \E{Z | \mathcal{F}_{n}}$ almost surely for all $n \geq 0$.
  \end{enumerate}
\end{thm}

\begin{thm}[Chapter 13 of Williams]
  \label{defn:discrete_time_martingales:14}
  Let $X_{n}, X \in L^{1}$ for all $n \geq 0$ and suppose that $X_{n}
  \cas X$ as $n \rightarrow \infty$.  Then $X_{n}$ converges to $X$ in
  $L^{1}$ if and only if $(X_{n})$ is uniformly integrable.
\end{thm}

\begin{proof}
  We proceed as follows.

  \begin{enumerate}
  \item[$~\ref{item:5} \Rightarrow \ref{item:6}$] Since $X$ is
    uniformly integrable, it is bounded in $L^{1}$ and by the
    martingale convergence theorem, we get that $X_{n}$ converges
    almost surely to a finite limit $X_{\infty}$.  By the previous
    theorem, Theorem \ref{defn:discrete_time_martingales:14} gives
    $L^{1}$ convergence.
  \item[$~\ref{item:6} \Rightarrow \ref{item:7}$] Set $Z =
    X_{\infty}$.  We need to show that $X_{n} = \E{Z |
      \mathcal{F}_{n}}$ almost surely for all $n \geq 0$. For all $m
    \geq n$ by the martingale property we have 
    \begin{align}
      \label{eq:43}
      \| X_{n} - \E{X_{\infty} | \mathcal{F}_{n}} \|_{1} = \| \E{X_{m}
      - X_{\infty} | \mathcal{F}_{n}} \|_{1} \leq \| X_{m}- X_{\infty}
    \|_{1} \rightarrow 0
    \end{align} as $m \rightarrow \infty$.
  \item[$~\ref{item:7} \Rightarrow \ref{item:5}$] $\E{Z |
      \mathcal{F}_{n}}$ is a martingale by the tower property of
    conditional expectation.  Uniform integrability follows from
    Theorem \ref{defn:discrete_time_martingales:11}.
  \end{enumerate}
\end{proof}

\begin{remark}
  If $X$ is UI then $X_{\infty} = \E{Z | \mathcal{F}_{\infty}}$ a.s
  where $F_{\infty} = \sigma(\mathcal{F}_{n}, n \geq 0)$.
\end{remark}

\begin{remark}
  If $X$ is a super/sub-martingale UI, then it converges almost surely
  and in $L^{1}$ to a finite limit $X_{\infty}$ with $\E{X_{\infty} |
    \mathcal{F}_{n}} (\geq) (\leq) X_{n}$ almost surely.
\end{remark}

\begin{exmp}
  \label{defn:discrete_time_martingales:15}
  Let $X_{1}, X_{2}, \dots$ be \iid random variables with $\Prob{X =
    0} = \Prob{X = 2} = \frac{1}{2}$.   Set $Y_{n}= X_{1}\cdot \dots
  \cdot X_{n}$.  Then $Y_{n}$ is a martingale.

  As $\E{Y_{n}} = 1$ for all $n$, we have $(Y_{n})$ is bounded in
  $L^{1}$, and it converges almost surely to 0.  But $\E{Y_{n}} = 1$
  for all $n$, and hence it does not converge in $L^{1}$.
\end{exmp}

If $X$ is a UI martingale and $T$ is a stopping time, then we can
unambiguously define
\begin{equation}
  \label{eq:44}
  X_{T} = \sum_{n=0}^{\infty} X_{n} \I{T = n} + X_{\infty} \I{T = \infty}
\end{equation}


\begin{thm}[Optional stopping for UI martingales]
  \label{defn:discrete_time_martingales:16}
  Let $X$ be a UI martingale and let $S, T$ be stopping times with $S
  \leq T$.  Then
  \begin{equation}
    \label{eq:45}
    \E{X_{T} | \mathcal{F}_{S}} = X_{S}    
  \end{equation} almost surely.
\end{thm}

\begin{proof}
  We first show that $\E{X_{\infty} | \mathcal{F}_{T}} = X_{T}$ almost
  surely for any stopping time $T$.  First, check that $X_{T} \in
  L^{1}$. Since $|X_{n}| \leq \E{|X_{\infty}| | \mathcal{F}_{n}}$, we
  have
  \begin{align}
    \label{eq:46}
    \E{|X_{T}|}= \sum_{n=0}^{\infty} \E{|X_{n}|\I{T=n} +
      \E{|X_{\infty}| \I{T = \infty}}} \\
    &\leq \sum_{n \in \Z^{+} \cup \{ \infty \}} \E{|X_{\infty}|
      \I{T=n}} \\
    &= \E{|X_{\infty}|}
  \end{align}  Let $B \in \mathcal{F}_{T}$. Then
  \begin{align}
    \label{eq:48}
    \E{\I{B} X_{T}} &= \sum_{n \in \Z^{+} \cup \{ \infty \}} \E{\I{B}
      \I{T=n} X_{n}} \\
    &= \sum_{n \in Z^{+} \cup \{ \infty \}} \E{\I{B} \I{T =n}
      X_{\infty}} \\
    &= \E{\I{B} X_{\infty}}
  \end{align} where for the second equality we used that
  $\E{X_{\infty} | \mathcal{F}_{n}} = X_{n}$ almost surely.

  Clearly $X_{T} is \mathcal{F}_{T}$-measurable, and hence
  $\E{X_{\infty} | \mathcal{F}_{T}} = X_{T}$ almost surely.  Using the
  tower property of conditional expectation, we have for stopping
  times $S \leq T$ (as $\mathcal{F}_{S} \subseteq \mathcal{F}_{T}$),
  \begin{align}
    \label{eq:49}
    \E{X_{T} | \mathcal{F}_{S}} = \E{\E{X_{\infty} | \mathcal{F}_{T}}
      | \mathcal{F}_{S}} \\
    &= \E{X_{\infty} | \mathcal{F}_{S}} \\
    &= X_{S}
  \end{align} almost surely.
\end{proof}

\section{Backwards Martingales}
\label{sec:backw-mart}

Let $... \subseteq \mathcal{G}_{-2} \subseteq G_{-1} \subseteq G_{0}$
be a sequence of $...$.
\todo{Fill in proof from lecture notes}

\section{Applications of Martingales}
\label{sec:appl-mart}

\begin{thm}[Kolmogrov's $0-1$ law]
  \label{defn:discrete_time_martingales:17}
  Let $(X_{i})_{i \geq 1}$ be a sequence of IID random variables.  Let
  $\mathcal{F}_{n} = \sigma(X_{k}, k \geq n)$ and
  $\mathcal{F}_{\infty} = \cap_{n \geq 0} \mathcal{F}_{n}$.  Then
  $\mathcal{F}_{\infty}$ is trivial - that is, every $A \in
  \mathcal{F}_{\infty}$ has probability $\Prob{A} \in \{ 0, 1 \}$.
\end{thm}

\begin{proof}
  Let $G_{n} = \sigma(X_{k}, k \leq n)$ and $A \in
  \mathcal{F}_{\infty}$.  Since $\mathcal{G}_{n}$ is independent of
  $\mathcal{F}_{n+1}$, we have that
  \begin{equation}
    \label{eq:47}
    \E{\I{A} | \mathcal{G}_{n}} = \Prob{A}
  \end{equation}
  Theorem 2.26 (LN \todo{link to correct theorem}) gives that
  $\Prob{A} = \E{\I{A} | \mathcal{G}_{n}}$ converges to $\E{\I{A} |
    \mathcal{G}_{\infty}}$ as $n \rightarrow \infty$, where
  $\mathcal{G}_{\infty} = \sigma(\mathcal{G}_{n}, n \geq 0)$.  Then we
  deduce that $\E{\I{A} | \mathcal{G}_{n}} = \I{A} = \Prob{A}$ as
  $\mathcal{F}_{\infty} \subseteq \mathcal{G}_{\infty}$.  Therefore,
  $\Prob{A} = $
\end{proof}

\begin{thm}[Strong law of large numbers]
  \label{defn:discrete_time_martingales:18}
  Let $(X_{i})_{i \geq 1}$ be a sequence of \iid random variables in
  $L^{1}$ with $\mu = \E{X_{i}}$.  Let $S_{n} = \sum_{i=1}^{n} X_{i}$
  and $S_{0} = 0$. Then $\frac{S_{n}}{n} \rightarrow \mu$ as $n
  \rightarrow \infty$ almost surely and in $L^{1}$.
\end{thm}

\begin{proof}
  \todo{fill in, this is somewhat involved.}
\end{proof}

\begin{thm}[Kakutani's product martingale theorem]
  \label{defn:discrete_time_martingales:19}
  Let $(X_{n})_{n \geq 0}$ be a sequence of independent non-negative
  random variables of mean 1.  Let $M_{0} = 1$, $M_{n} =
  \prod_{i=1}^{n} X_{i}$ for $n \in \N$.  Then $(M_{n})_{n \geq 0}$ is
  a non-negative martingale and $M_{n} \rightarrow M_{\infty}$ a.s.
  as $n \rightarrow \infty$ for some random variable $M_{\infty}$.  We
  set $a_{n = \E{\sqrt{X_{n}}}}$, then $a_{n}\in (0, 1]$.  Moreover,
  \begin{enumerate}
  \item If $\prod_{n} a_{n} > 0$, then $M_{n} \rightarrow M_{\infty}$
    in $L^{1}$ and $\E{M_{\infty}} = 1$,
  \item If $\prod_{n} a_{n} = 0$, then $M_{\infty} = 0$ almost surely.
  \end{enumerate}
\end{thm}

\begin{proof}
  \todo{fill in}
\end{proof}


\subsection{Martingale proof of the Radon-Nikodym theorem}
\label{sec:mart-proof-radon}

Let $\Prob, \Q$ be two probability measures on the measurable space
$\Omega, \mathcal{F}$.  Assume that $\mathcal{F}$ is countably
generated, that is, there exists a collection of sets $(F_{n})_{n \in
  \N}$ such that $\mathcal{F} = \sigma(F_{N}, n \in \N)$. Then the
following are equivalent.
\begin{enumerate}
\item \label{item:8} $\Prob{A} = 0 \Rightarrow  \Q{A}$ for all $A \in \mathcal{F}$.
  That is, $\Q$ is absolutely continuous with respect to $\Prob$ and
  write $\Q << \Prob$
\item \label{item:9} For all $\epsilon > 0$, there exists $\delta > 0$ such that
  $\Prob{A} \leq \delta \Rightarrow \Q{A} \leq \epsilon$.
\item \label{item:10} There exists a non-negative random variable $X$ such that
  \begin{equation}
    \label{eq:50}
    \Q{A} = \E{X\I{A}}{\Prob}
  \end{equation}
\end{enumerate}

\begin{proof}
  $\ref{item:8} \rightarrow \ref{item:9}$.  If $\ref{item:9}$ does not
  hold, then there exists $\epsilon > 0$ such that for all $n \geq 1$
  there exists a set $A_{n}$ with $\Prob{A_n} \leq \frac{1}{n^{2}}$
  and $\Q{A_{n}} \geq \epsilon$.  By Borel-Cantelli, we get that
  $\Prob{A_{n} i.o} = 0$.  Therefore from $\ref{item:8}$ we get that
  $\Q{A_{n} i.o} = 0$.  But
  \begin{equation}
    \label{eq:51}
    \Q{A_{n} i.o} = \Q{\cap_{n} \cup_{k \geq n} A_{k}} = \lim_{n
      \rightarrow \infty} Q(\cup_{k \geq n} A_{k}) \geq \epsilon
  \end{equation} which is a contradiction.


  $\ref{item:9} \rightarrow \ref{item:10}$. Consider the filtration
  $\mathcal{F}_{n} = \sigma(F_{k}, k \leq n)$.  Let
  \begin{equation}
    \label{eq:52}
    \mathcal{A}_{n} = \{ H_{1} \cap \dots \cap H_{n} | H_{i} = F_{i}
    \text{ or } F_{i}^{c} \}
  \end{equation} then it is easy to see that $\mathcal{F}_{n} =
  \sigma(A_{n})$.  Note also that sets in $A_{n}$ are disjoint.

  \todo{continue proof}
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "master"
%%% End:
