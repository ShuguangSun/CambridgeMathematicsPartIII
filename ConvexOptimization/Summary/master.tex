\input{../../common/summary.tex}

\title{Convex Optimization Summary}

\begin{document}

\maketitle

\section{Existence}
\label{sec:existence}

\begin{defn}
  \label{sec:existence-1}
  For $C \subseteq \R^{n}$, define $\delta_{C}$ as
  \begin{equation}
    \label{eq:1} \delta_{C}(x) = 
    \begin{cases}
      0 & x \in C \\
      \infty & x \notin C
    \end{cases}
  \end{equation}

  Note $x'$ minimizes $f$ over $C$ if and only if $x'$ minimizes $f +
  \delta_{C}$ over $\R^{n}$.
\end{defn}

\begin{defn}
  \label{sec:existence-2}
  \begin{enumerate}
  \item $\dom f = \{ x \in \R^{n} | f(x) < \infty \}$,
  \item \begin{equation}
      \argmin f =
      \begin{cases}
        \emptyset & f \equiv \infty \\
        \{ x \in \R^{n} | f(x) = \inf f \} & f < \infty 
      \end{cases}
    \end{equation}
  \item $f$ is \textbf{proper} if and only if $\dom f \neq \emptyset$
    and $f(x) > -\infty$ for all $x \in \R^{n}$.
  \end{enumerate}
\end{defn}

\begin{defn}
  \label{sec:existence-3}
  For $f: \R^{n} \rightarrow \overline \R$, denote
  \begin{equation}
    \label{eq:2}
    \epi f = \{ (x, \alpha) \in \R^{n} \times \R | f(x) \leq \alpha \} 
  \end{equation}
\end{defn}

\begin{thm}
  \label{sec:existence-4}
  A set $C$ is an epigraph if and only if for every $x$ there is an
  $\alpha \in \overline \R$ such that $C \cap (x \times \R) = [\alpha,
  \infty]$ - so all vertical one-dimensional sections must be closed
  upper half-lines. If $f$ is proper then $\epi f $ is not empty and
  does not include a complete vertical line.
\end{thm}

\begin{defn}
  \label{sec:existence-5}
  For $f: \R^{n} \rightarrow \overline \R$, define
  \begin{equation}
    \label{eq:3}
    \liminf_{x \rightarrow x'} f(x) = \lim_{\delta \downarrow 0}
    \inf_{\| x - x'\|_{2} \leq \delta} f(x) = \lim_{k \rightarrow
      \infty} \inf_{\| x - x'\|_{2} \leq \frac{1}{k}} f(x)
  \end{equation}
  $f$ is \textbf{lower semicontinuous} at $x'$ if and only if $f(x')
  \leq \liminf_{x \rightarrow x'} f(x)$.
  $f$ is \textbf{lower semicontinous} if $f$ is lower semicontinous at
  every $x' \in \R^{n}$.
\end{defn}

\begin{thm}
  \label{sec:existence-7}
  \begin{equation}
    \label{eq:4}
    \liminf_{x \rightarrow x'} f(x) = \min \{ \alpha \in \overline \R
    | \exists (x^{k}) \rightarrow x' : f(x^{k}) \rightarrow \alpha \}
  \end{equation}
  In particular, $f$ is lower semi-continuous at $x'$ if and only if
  $f(x') \leq \liminf_{k \rightarrow \infty} f(x^{k})$ for all
  convergence sequences $x^{k} \rightarrow x'$.
\end{thm}

\begin{thm}
  \label{sec:existence-8}
  Let $f: \R^{n} \rightarrow \overline \R$.  Then the following are
  equivalent:
  \begin{enumerate}
  \item $f$ is lsc on $\R^{n}$
  \item $\epi f$ is closed in $\R^{n} \times \R$
  \item The sub level sets $\lev_{\leq \alpha} f = \{ x \in \R^{n} |
    f(x) \leq \alpha \} $ are closed in $\R^{n}$ for all $\alpha \in
    \overline \R$.
  \end{enumerate}
\end{thm}

\begin{defn}
  \label{sec:existence-9}
  $f: \R^{n} \rightarrow \overline \R$ is level bounded if and only if
  $\lev_{\leq \alpha} f$ is bounded for all $\alpha \in \R$.
\end{defn}

\begin{defn}
  \label{sec:existence-10}
  $f: \R^{n} \rightarrow \overline \R$ is level-bounded if and only if
  $f(x^{k}) \rightarrow \infty$ for all sequences $(x^{k})$ satisfying
  $\| x^{k} \|_{2} \rightarrow \infty$.
\end{defn}

\begin{thm}
  \label{sec:existence-11}
  Assume $f: \R^{n} \rightarrow \overline \R$ is lsc, level-bounded,
  and proper.  Then $\inf f(x) \in (-\infty, +\infty)$ and $\argmin f$
  is nonempty and compact.
\end{thm}

\begin{thm}
  \label{sec:existence-12}
  \begin{enumerate}
  \item $f, g$ lsc, proper implies $f + g$ is lsc.
  \item $f$ lsc, $\lambda \geq 0$ implies $\lambda f$ is lsc
  \item $f: \R^{n} \rightarrow \overline \R$ is lsc and $g: \R^{m}
    \rightarrow \R^{n}$ is continuous implies $f \circ g$ is lsc.
  \end{enumerate}
\end{thm}

\section{Convexity}
\label{sec:convexity}

\begin{defn}
  \label{sec:convexity-1}
  $f: \R^{n} \rightarrow \overline \R$ is convex if and only if
  \begin{equation}
    \label{eq:5}
    f((1 - \tau)x + \tau y) \leq (1 - \tau) f(x) + \tau f(y)
  \end{equation} for all $x, y \in \R^{n}, \tau \in (0, 1)$.

  A set $C \subseteq \R^{n}$ is convex if and only if $\delta_{C}$ is
  convex if and only if $(1 - \tau) x + \tau y \in C$ for all $x, y
  \in C, \tau \in (0, 1)$.

  $f: \R^{n} \rightarrow \overline \R$ is strictly convex if and only
  if $f$ is convex and the inequality is strict for all $x \neq y$ and
  $\tau \in (0, 1)$.
\end{defn}

\begin{defn}
  \label{sec:convexity-2}
  Let $x_{0}, \dots, x_{m} \in \R^{n}$  and $\lambda_{0}, \dots,
  \lambda_{m} \geq 0$, $\sum_{i=0}^{m} \lambda_{i} = 1$.  The linear
  combination $\sum_{i=0}^{m} \lambda_{i} x_{i}$ is a \textbf{convex
  combination} of the points $x_{0}, \dots, x_{m}$.
\end{defn}

\begin{thm}
  \label{sec:convexity-3}
  \begin{enumerate}
  \item $f: \R^{n} \rightarrow \overline \R$ is convex if and only if
    \begin{equation}
      \label{eq:6}
      f(\sum_{i=0}^{m} \lambda_{i} x_{i}) \leq \sum_{i=0}^{m}
      \lambda_{i} f(x_{i})
    \end{equation} for all $m \geq 0, x_{i} \in \R^{n}, \lambda_{i}
    \geq 0, \sum_{i=0}^{m} \lambda_{i} = 1$.
  \item $C \subseteq \R^{n}$ is convex if and only if $C$ contains all
    convex combinations of its elements.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-4}
  $f: \R^{n} \rightarrow \overline \R$ is convex implies $\dom f$ is convex.
\end{thm}

\begin{thm}
  \label{sec:convexity-5}
  \begin{enumerate}
  \item $f: \R^{n} \rightarrow \overline \R$ is convex if and only if
    $\epi f$ is convex in $\R^{n} \times \R$.
  \item $f: \R^{n} \rightarrow \overline \R$ is strictly convex if and only if
    $\{ (x, \alpha) \in \R^{n} \times \R | f(x) < \alpha \} $ is
    convex in $\R^{n} \times \R$.
  \item $f: \R^{n} \rightarrow \overline \R$ is convex implies
    $\lev_{\leq \alpha} f$ is convex for all $\alpha \in \overline \R$.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-7}
  Assume $f: \R^{n} \rightarrow \overline \R$ is convex. Then
  \begin{enumerate}
  \item $\argmin f$ is convex.
  \item $x$ is a local minimizer of $f$ implies $x$ is a global
    minimize of $f$.
  \item $f$ is strictly convex and proper impiles $f$ has at most one
    global minimizer.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-8}
  Let $I$ be an arbitrary index set. Then
  \begin{enumerate}
  \item $f_{i}, i \in I$ convex implies $\sup_{i \in I} f_{i}(x)$ is
    convex.
  \item $f_{i}, i \in I$ strictly convex, $I$ finite implies $\sup_{i
      \in I} f_{i}(x)$ is strictly convex.
  \item $C_{i}, i \in I$ is convex implies $\cap_{i \in I} C_{i}$ is convex.
  \item $f_{k}, k \in N$ is convex implies $\limsup_{k \rightarrow
      \infty} f_{k}(x)$ is convex.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-9}
  Assume $C \subseteq \R^{n}$ is open and convex, and $f: C
  \rightarrow \R$ is differentiable. Then the following are
  equivalent:
  \begin{enumerate}
  \item $f$ is [strictly] convex
  \item $\IP{y-x, \grad f(y) - \grad f(x)} \geq 0$ for all $x, y \in
    C$ [and $> 0$ if $x \neq y$]
  \item $f(x) + \IP{y- x, \grad f(x)} \leq f(y)$ for all $x, y \in C$
    [and $< f(y)$ if $x \neq y$]
  \item If $f$ is additionally twice differentiable, then $\grad^{2}
    f(x)$ is positive semidefinite for all $x \in C$.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-10}
  \begin{enumerate}
  \item Assume $f_{1}, \dots, f_{m}: \R^{n} \rightarrow \overline \R$
    are convex, $\lambda_{1}, \dots, \lambda_{m} \geq 0$.  Then $f =
    \sum_{i=1}^{m} \lambda_{i} f_{i}$ is convex.  If at least one of
    the $f_{i}$ with $\lambda_{i} > 0$ is strictly convex, then $f$ is
    strictly convex.
  \item Asssume $f_{i}: \R^{n_{i}} \rightarrow \overline \R$ are
    convex.  Then
    \begin{align}
      \label{eq:7}
      f: \R^{n_{1}} \times \dots R^{n_{m}} \rightarrow \overline \R
      f(x_{1}, \dots, x_{m}) = \sum_{i=1}^{m} f_{i}(x_{i})
    \end{align} is convex. If all $f_{i}$ are strictly convex, then
    $f$ is strictly convex.
  \item If $f: \R^{m} \rightarrow \overline \R$ is convex, $A \in
    \R^{m \times n}, b \in \R^{m}$.  Then $g(x) = f(Ax + b)$ is convex.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-11}
  \begin{enumerate}
  \item $C_{1}, \dots, C_{m}$ convex implies $C_{1} \times \dots
    \times C_{m}$ is convex.
  \item $C \subseteq \R^{n}$ convex, $A \in \R^{m \times n}$, $b \in
    \R^{m}$, $L(x) = Ax + b$ implies $L(C)$ is convex.
  \item $C \subseteq \R^{m}$ convex, $A \in \R^{m \times n}$, $b \in
    \R^{m}$, $L(x) = Ax + b$ implies $L^{-1}(C)$ is convex.
  \item $C_{1}, C_{2}$ is convex implies $C_{1} + C_{2}$ is convex.
  \item $C$ convex, $\lambda \in \R$ implies $\lambda C$ is convex.
  \end{enumerate}
\end{thm}

\begin{defn}
  \label{sec:convexity-12}
  For a set $S \subseteq \R^{n}$ and $x \in \R^{n}$, define the
  projection of $x$ onto $S$ as
  \begin{equation}
    \label{eq:9}
    \proj_{S}(y) = \argmin_{x \in S} \|x - y\|_{2}.
  \end{equation}
\end{defn}

\begin{thm}
  \label{sec:convexity-13}
  Assume $C \subseteq \R^{n}$ is convex, closed, and $C \neq
  \emptyset$.  Then $\proj_{C}$ is single-valued - that is, the
  projection of $x$ onto $C$ is unique for every $x \in \R^{n}$.
\end{thm}

\begin{defn}
  \label{sec:convexity-14}
  For an arbitary set $S \subseteq \R^{n}$,
  \begin{equation}
    \label{eq:10}
    \con S = \bigcap_{\text{$C$ convex, $S \subseteq C$}} C
  \end{equation}
  is the convex hull of $S$.  It is the smallest convex set that
  contains $S$.
\end{defn}

\begin{thm}
  \label{sec:convexity-15}
  $\con S = \{ \sum_{i=0}^{p} \lambda_{i} x_{i} | x_{i} \in S,
  \lambda_{i} \geq 0, \sum_{i=0}^{p} \lambda_{i} = 1, p \geq 0  \}$
\end{thm}


\begin{thm}
  \label{sec:convexity-16}
  \begin{enumerate}
  \item $\cl C = \{ x \in \R^{n} | \text{for all open neighbourhoods
      $N$ of $x$, $N \cap C \neq \emptyset$} \}$
  \item $\int C = \{ x \in \R^{n} | \text{there exists an open
      neighbourhood $N$ of $x$ such that $N \subseteq C$} \} $
  \item $\bnd C = \cl C \backslash \int C$.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:convexity-17}
  $\cl C = \bigcap_{\text{$S$ closed, $C \subseteq S$}} S$.
\end{thm}

\section{Cones and Generalized Inequalities}
\label{sec:cones-gener-ineq}

\begin{defn}
  \label{sec:cones-gener-ineq-1}
  $K \subseteq \R^{n}$ is a cone if and only if $0 \in K$ and $\lambda
  x \in K$ for all $x \in K, \lambda \geq 0$.

  A cone $K$is pointed if and only if $\sum_{0=1}^{m} x_{i} = 0$,
  $x_{i} \in K$ implies $x_{i} = 0$ for all $i$.
\end{defn}

\begin{thm}
  \label{sec:cones-gener-ineq-2}
  Let $K \subseteq \R^{n}$ be arbitrary. Then the following are equivalent:
  \begin{enumerate}
  \item $K$ is a convex cone.
  \item $K$ is a cone and $K + K \subseteq K$.
  \item $K \neq \emptyset$ and $\sum_{i=0}^{m} \alpha_{i} x_{i} \in K$
    for all $x_{i} \in K$ and $\alpha_{i} \geq 0$ (not necessarily
    summing to 1).
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:cones-gener-ineq-4}
  Assume $K$ is a convex cone.  Then $K$ is pointed if and only if $K
  \cap -K = \{ 0 \} $.
\end{thm}

\begin{thm}
  \label{sec:cones-gener-ineq-5}
  For a closed convex cone $K \subseteq \R^{n}$ we define the
  generalized inequality
  \begin{equation}
    \label{eq:11}
    x \leq_{K} y \iff x - y \in K
  \end{equation}

  Then
  \begin{enumerate}
  \item $x \leq_{K} x$
  \item $x \leq_{K} y, y \leq_{K} z \Rightarrow x \leq_{K} z$
  \item $x \leq_{K} y \Rightarrow -y \leq_{K} -x$
  \item $x \leq_{K} y, \lambda \geq 0 \Rightarrow \lambda x \geq_{K}
    \lambda y$
  \item $x \geq_{K} y, x' \geq_{K} y' \Rightarrow x + x' \geq_{K} y + y'$
  \item $x^{k} \rightarrow x$, $y^{k} \rightarrow y$ with $x^{k}
    \geq_{K} y^{K}$ for all $k \in \N$, then $x \geq_{K} y$.
  \item $x \geq_{K} y, y \geq_{K} \Rightarrow x = y$ (antisymmetry)
    holds if and only if $K$ is pointed.
  \end{enumerate}
\end{thm}

\begin{defn}
  \label{sec:cones-gener-ineq-6}
  For any pointed, closed, convex cone $K \subseteq \R^{m}$, a matrix
  $A \in \R^{m \times n}$, and vectors $c \in \R^{n}, b \in \R^{m}$,
  define the conic problem $\inf_{x} c^{T} x s.t. Ax \geq_{K} b$.
\end{defn}

\section{Subgradients}
\label{sec:subgradients}

\begin{defn}
  \label{sec:subgradients-1}
  For any $f: \R^{n} \rightarrow \overline \R$ and $x \in \R^{n}$,
  \begin{equation}
    \label{eq:12}
    \partial f(x) = \{ v \in \R^{n} | f(x) + \IP{v, y -x} \leq f(y)
    \forall y \in \R^{n} \} 
  \end{equation} is the set of subgradients of $f$ at $x$. 
\end{defn}

\begin{thm}
  \label{sec:subgradients-3}
  Assume $f, g: \R^{n} \rightarrow \overline \R$ are convex.  Then
  \begin{enumerate}
  \item If $f$ is differentiable at $x$, then $\partial f(x) = \{
    \grad f(x) \} $
  \item If $f$ is differentiable at $x$ and $g(x) \in \R$, then
    $\partial (f +g)(x) = \partial g(x) + \grad f(x)$.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:subgradients-4}
  Assume $f: \R^{n} \rightarrow \overline \R$ is proper.  Then $x \in
  \argmin f \iff 0 \in \partial f(x)$.
\end{thm}

\begin{defn}
  \label{sec:subgradients-5}
  For a convex set $C \subseteq \R^{n}$ and $x \in C$, the normal cone
  $N_{C}(x)$ at $x$ is
  \begin{equation}
    \label{eq:13}
    N_{C}(x = \{ v \in \R^{n} | \IP{v, y -x } \leq 0 \forall y \in C \} )
  \end{equation}  $N_{C}(x) = \emptyset$ for $x \notin C$.

  Note that $N_{C}(x)$ is a cone if $x \in C$.
\end{defn}

\begin{thm}
  \label{sec:subgradients-6}
  Assume $C \subseteq \R^{n}$ is convex with $C \neq \emptyset$.  Then
  $\partial \delta_{C}(x) = N_{C}(x)$.
\end{thm}
\begin{thm}
  \label{sec:subgradients-7}
  Assume $C \subseteq \R^{n}$ is closed and convex with $C \neq
  \emptyset$ and $x \in \R^{n}$.  Then $y \in \proj_{C}(x) \iff x - y
  \in N_{C}(y)$.
\end{thm}

\begin{thm}
  \label{sec:subgradients-8}
  Assume $f: \R^{n} \rightarrow \overline \R$ is proper and convex.
  Then
  \begin{equation}
    \label{eq:14}
    \partial f(x) =
    \begin{cases}
      \emptyset & x \notin \dom f \\
      \{ v \in \R^{n} | (v, -1) \in N_{\epi f}(x, f(x)) \} & x \in
      \dom f
    \end{cases}
  \end{equation}

  If $x \in \dom f$ then $N_{\dom f}(x) = \{ v \in \R^{n} | (v, 0) \in
  N_{\epi f}(x, f(x)) \} $.
\end{thm}

\begin{defn}
  \label{sec:subgradients-10}
  For any set $C \subseteq \R^{n}$, define the affine hll and relative
  interior by
  \begin{align}
    \label{eq:15}
    \aff C = \cap_{\text{$A$ affine, $C \subseteq A$}} A \\
    \rint C = \{ x \in \R^{n} | \text{there exists an open
      neighbourhood $N$ of $x$ with $N \cap \aff C \subseteq C$} \}.
    \label{eq:16}
  \end{align}
\end{defn}

\begin{thm}
  \label{sec:subgradients-11}
  \begin{enumerate}
  \item Assume $f: \R^{n} \rightarrow \overline \R$  is convex. Then
    \begin{align}
      \label{eq:17}
      g(x) = f(x+y) \Rightarrow \partial g(x) = \partial f(x+y) \\
      g(x) = f(\lambda x) \Rightarrow \partial g(x) = \lambda \partial
      f(\lambda x), \lambda \neq 0 \\
      \label{eq:19}
      g(x) = \lambda f(x) \Rightarrow \partial g(x) = \lambda \partial
      f(x), \lambda > 0 \\
    \end{align}
  \item Assume $f: \R^{n} \rightarrow \overline \R$ is proper and
    convex, and $A \in \R^{n \times m}$ is such that
    \begin{equation}
      \label{eq:21}
      \{ Ay | y \in \R^{m} \}  \cap \rint \dom f
    \end{equation}
    If $x \in \dom (f \circ A) = \{ y \in \R^{m} | Ay \in \dom f \} $,
    then $\partial (f \circ A)(x) = A^{T} \partial f(Ax)$.
  \item Assume $f_{0}, \dots, f_{m}: \R^{n} \rightarrow \overline \R$
    are proper and convex, and $\rint \dom f_{0} \cap \dots \cap \rint
    \dom f_{m} \neq \emptyset$.  If $x \in \dom f$, then
    $\partial(\sum_{i=0}^{m} f_{i})(x) = \sum_{i=0}^{m} \partial f_{i}(x)$.
  \end{enumerate}
\end{thm}

\section{Conjugate Functions}
\label{sec:conjugate-functions}

\begin{defn}
  \label{sec:conjugate-functions-1}
  For $f: \R^{n} \rightarrow \overline \R$, $\con f(x) =\sup_{\text{$g
      \leq f$, $g$ convex}}$ is the convex hull of $f$.
  $\con f$ is the greatest convex function majorized by $f$.
\end{defn}

\begin{defn}
  \label{sec:conjugate-functions-2}
  For $f: \R^{n} \rightarrow \overline \R$, the \textbf{lower closure}
  $\cl f$ is defined as $(\cl f)(x) = \liminf_{y \rightarrow x} f(y)$.
  Alternatively, $(\cl f)(x) = \sup_{\text{$g \leq f$, $g$ lsc}} g(x)$.
\end{defn}

\begin{thm}
  \label{sec:conjugate-functions-3}
  For $f: \R^{n} \rightarrow \overline \R$, we have $\epi (\cl f) =
  \cl (\epi f)$.  Moreover, if $f$ is convex then $\cl f$ is convex.
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-4}
  Assume $C \subseteq \R^{n}$ is closed and convex.  Then $C =
  \bigcap_{(b, \beta), C \subseteq H_{b, \beta}} H_{b, \beta}$ where
  $B_{b, \beta} = \{ x \in \R^{n} | \IP{x, b} - \beta \leq 0 \} $
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-5}
  Assume $f: \R^{n} \rightarrow \overline \R$ is proper, lsc, and
  convex.  Then $f(x) = \sup_{\text{$g$ affine, $f \leq f$}} g(x)$.
\end{thm}

\begin{defn}
  \label{sec:conjugate-functions-6}
  Let $f: \R^{n} \rightarrow \overline \R$, then
  \begin{align}
    \label{eq:8}
    f^{\star}: \R^{n} \rightarrow \overline \R \\
    f^{\star}(v) = \sup_{x \in \R^{n}} \IP{v, x} - f(x)
  \end{align} is the \textbf{conjugate to $f$}.  The mapping $f
  \mapsto f^{\star}$ is the Legendre-Fenchel transform.
\end{defn}

\begin{thm}
  \label{sec:conjugate-functions-7}
  Assume $f: \R^{n} \rightarrow \overline \R$.  Then $f^{\star} =
  (\con f)^{\star} = (\cl f)^{\star} = (\cl \con f)^{\star}$ and
  $f^{\star \star} = (f^{\star})^{\star} \leq f$ .  If $\con f$ is
  proper, then $f^{\star}$ and $f^{\star \star}$ are proper, lsc, and
  convex, and $f^{\star \star} = \cl \con f$.  If $f: \R^{n}
  \rightarrow \overline \R$ is proper, lsc, and convex, then $f^{\star
  \star} = f$.
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-8}
  Assume $f: \R^{n} \rightarrow \overline \R$.  Then
  \begin{enumerate}
  \item $\con f$ is not proper implies $f^{\star} \equiv +\infty$ or
    $f^{\star} \equiv -\infty$.
  \item In particular, $f^{\star}$ proper implies $\con f$ is proper.
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-9}
  Assume $f: \R^{n} \rightarrow \overline \R$ is proper, lsc, and
  convex.  Then $\partial f^{\star} = (\partial f)^{-1}$,
  specifically,
  \begin{equation}
    \label{eq:20}
    v \in \partial f(x) \iff f(x) + f^{\star}(v) = \IP{v, x} \iff x
    \in \partial f^{\star}(v).
  \end{equation}
  Moreover,
  \begin{align}
    \label{eq:22}
    \partial f(x) = \argmax_{v'} \IP{v', x} - f^{\star}(v')
    \partial f^{\star}(x) = \argmax_{x'} \IP{v, x'} - f(x)
  \end{align}
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-10}
  For a proper, lsc, convex $f: \R^{n} \rightarrow \overline \R$, we
  have
  \begin{align}
    \label{eq:23}
    (f(\cdot) - \IP{a, \cdot})^{\star} = f^{\star}(\cdot + a) \\
    \label{eq:24}
    (f(\cdot + b))^{\star} = f^{\star}(\cdot) - \IP{\cdot, b}, \\
    \label{eq:25}
    (f(\cdot) + c)^{\star} = f^{\star}(\cdot) - c \\
    \label{eq:26}
    (\lambda f(\cdot))^{\star} = \lambda
    f^{star}(\frac{\cdot}{\lambda}), \lambda > 0 \\
    \label{eq:27}
    (\lambda f(\frac{\cdot}{\lambda} ))^{\star} = \lambda
    f^{\star}(\cdot), \lambda > 0
  \end{align}
\end{thm}

\begin{thm}
  \label{sec:conjugate-functions-11}
  Let $f_{i}: \R^{n_{i}} \rightarrow \overline \R$, $i = 0, \dots, m$
  be proper and $f(x_{0}, \dots, x_{m}) = \sum_{i=0}^{m}
  f_{i}(x_{i})$.  Then $f^{\star}(v_{1}, \dots, v_{m}) = \sum_{i=0}^{m} f^{\star}_{i}(v_{i})$.
\end{thm}

\begin{defn}
  \label{sec:conjugate-functions-12}
  For any set $S \subseteq \R^{n}$ define the \textbf{support
    function} $\supp_{S}(v) = \sup_{x \in S} \IP{v, x} = (\delta^{\star}_{S})(v)$
\end{defn}

\begin{defn}
  \label{sec:conjugate-functions-13}
  A function $f: \R^{n} \rightarrow \overline \R$ is said to be
  positively homogenous if and only if $0 \in \dom f$ and $f(\lambda
  x) = \lambda f(x)$ for all $x \in \R^{n}$ and $\lambda > 0$.
\end{defn}

\begin{thm}
  \label{sec:conjugate-functions-14}
  The set of positively homogenous proper lsc convex functions and the
  set of closed convex nonempty sets are in one-to-one correspondence
  through the Legendre-Fenchel transform:
  \begin{align}
    \label{eq:28}
    \delta_{C} \leftrightarrow_{\star} \supp_{C} \\
    \label{eq:29}
    x \in \partial \supp_{C}(v) \iff x \in C \\
    \label{eq:30}
    \supp_{C}(v) = \IP{v, x} \iff v \in N_{C}(x).
  \end{align}

  In particular, the set of closed convex cones is in one-to-one
  correspondence with itself - for any cone $K$ define the
  \textbf{polar cone} or \textbf{dual cone} as $K^{\star} = \{ v \in
  \R^{d} | \IP{v, x} \leq 0 \forall x \in K \} $.  Then
  \begin{align}
    \label{eq:31}
    \delta_{K} \leftrightarrow_{\star} \delta_{K^{\star}} \\
    \label{eq:32}
    x \in N_{K^{\star}}(v) \iff v \in N_{K}(x) % \iff x \in K, v \in
    % K^{\star}, \IP{x, v} = 0 \iff 0 \leq_{K} x \perp v
    % \geq_{K^{\star}} 0
  \end{align}
  TODO: fill next condition/implication in.
\end{thm}

\section{Duality in Optimization}
\label{sec:duality-optimization}

\begin{defn}
  \label{sec:duality-optimization-1}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, and convex.  Define the \textbf{primal problem} as
  \begin{equation}
    \label{eq:33}
    \inf_{x \in \R^{n}} \phi(x), \phi(x) = f(x, 0),
  \end{equation} the \textbf{dual problem} as
  \begin{equation}
    \label{eq:34}
    \sup_{y \in \R^{n}} \psi(y), \psi(y) = -f^{\star}(0, y)
  \end{equation}
  and the \textbf{inf-projections}
  \begin{align}
    \label{eq:35}
    p(u) = \inf_{x} f(x, u) \\
    \label{eq:36}
    q(v) = \inf_{y} f^{\star}(v, y) = -\sup_{y} (-f^{\star}(v, y))
  \end{align}
  $f$ is sometimes called a \textbf{peturbation function} for $\psi$,
  and $p$ the associated \textbf{marginal function}.
\end{defn}

\begin{thm}
  \label{sec:duality-optimization-2}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, and convex.  Then
  \begin{enumerate}
  \item $\phi$ and $-\psi$ are lsc and convex.
  \item $p, q$ are convex.
  \item $p(0)$ and $p^{\star \star}(0)$ are the optimal values of the
    primal and dual problems -
    \begin{align}
      \label{eq:37}
      p(0)  = \inf_{x} \phi(x), p^{\star \star}(0) = \sup_{y} \psi(y).
    \end{align}
  \item The primal and dual problems are feasible if and only if their
    associated marginal function contains 0:
    \begin{align}
      \label{eq:38}
      \inf_{x} \phi(x) < \infty \iff 0 \in \dom p \\
      \label{eq:39}
      \sup_{y} \psi(y) > -\infty \iff 0 \in \dom q
    \end{align}
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-4}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, and convex. Then \textbf{weak duality} always holds,
  \begin{equation}
    \label{eq:40}
    \inf_{x} \phi(x) \geq \sup_{y} \psi(y),
  \end{equation} and under certain conditions the infimum and supremum
  are equal and finite - \textbf{strong duality}
  \begin{equation}
    \label{eq:41}
    p(0) \in \R, \text{$p$ lsc in $0$} \iff \inf_{x} \phi(x) =
    \sup_{y} \psi(y) \in \R.
  \end{equation}
  The difference $\inf \phi - \sup \psi$ is the \textbf{duality gap}.
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-5}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, and convex.  Then we have the \textbf{primal-dual optimality
    conditions},
  \begin{align}
    \label{eq:42}
    (0, y') \in \partial f(x', 0) \iff \{ x' \in \argmin_{x} \phi(x),
    y' \in \argmax_{y} \psi(y), \inf_{x} \psi(x) = \sup_{y} \psi(y) \}
    \iff (x', 0) \in \partial f^{\star}(0, y').
  \end{align}

  The set of \textbf{primal-dual optimal points} $(x', y')$ satisfying
  this equation is either empty or equal to $(\argmin \phi) \times
  (\argmax \psi)$.
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-6}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, and convex. Then
  \begin{enumerate}
  \item\label{item:1} $0 \in \interior \dom p$ or $0 \in \interior \dom q$ implies
    $\inf_{x} \phi(x) = \sup_{y} \psi(y)$.
  \item\label{item:2} $0 \in \interior \dom p$ and $0 \int \interior \dom q$ implies
    $\inf_{x} \phi(x) = \sup_{y} \psi(y) \in \R$.
  \item\label{item:3} $0 \in \int \dom p$ and $\inf_{x} \phi(x) \in \R$ if and only
    if $\argmax_{y} \psi(y)$ is nonempty and bounded.
  \item\label{item:4} $0 \in \int \dom q$ and $\sup_{y} \psi(y) \in \R$ if and only
    if $\argmin_{x} \phi(x)$ is nonempty and bounded.
  \end{enumerate}
  In particular, if any of \ref{item:2}, \ref{item:3}, \ref{item:4}
  hold, then strong duality holds - $\inf \phi = \sup \psi \in \R$.
  If \ref{item:2}, or (\ref{item:3} and \ref{item:4} hold), then there
  exists $x', y'$ satisfying the primal-dual optimality conditions.
  Also, \ref{item:3} implies $\partial p(0) = \argmax_{y} \psi(y)$,
  and \ref{item:4} implies $\partial q(0) = \argmin_{x} \phi(x)$.
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-7}
  Assume $k: \R^{n} \rightarrow \overline \R$ and $h: \R^{m}
  \rightarrow \overline \R$ are both proper, lsc, convex, and $A \in
  \R^{m \times n}, b \in \R^{m}, c \in \R^{n}$.  For $f(x, u) = \IP{c,
  x} + k(x) + h(Ax - b + u)$, the primal and dual problems are of the
form
\begin{align}
  \label{eq:43}
  \inf \phi(x), \phi(x) = \IP{c, x} + k(x) + h(Ax - b) \\
  \label{eq:44}
  \sup_{y} \psi(y), \psi(y) = -\IP{b, y} - h^{\star}(y) -
  k^{\star}(-A^{T}y - c)
\end{align} with
\begin{align}
  \label{eq:45}
  \int \dom p = \int (\dom h - A \dom k) + b \\
  \label{eq:46}
  \int \dom q = \int(\dom k^{\star} - (-A^{T}) \dom h^{\star}) + c
\end{align}
and optimality conditoins
\begin{align}
  \label{eq:47}
  \{ -A^{T} y' - c \in \partial k(x'), y' \in \partial h(Ax' - b) \}
  \iff \{ x' \in \argmin_{x} \phi(x), y' \in \argmax_{y} \psi(y),
  \inf_{x} \phi(x) = \sup_{y} \psi(y) \} \iff \{ Ax' - b \in \partial
  h^{\star}(y'), x' \in \partial k^{\star}(-A^{T} y' - c) \} 
\end{align}
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-8}
  Assume $f: \R^{n} \times \R^{m} \rightarrow \overline \R$ is proper,
  lsc, convex.  Define the associated \textbf{Lagrangian} as $l(x, y)
  = -f(x, \cdot)^{\star}(y)$, so $l(x, y) = \inf_{u}(f(x, u) - \IP{y,
    u})$.  Then $l(\cdot, y)$ is convex for every $y$, $-l(x, \cdot)$
  is lsc and convex for every $x, y$ and $f(x, \cdot) = (-l(x,
  \cdot))^{\star}$, and $(v, y) \in \partial f(x, u) \iff v
  \in \partial_{x} l(x, y) \text{ and } u \in \partial_{y}(-l)(x, y)$.
\end{thm}

\begin{defn}
  \label{sec:duality-optimization-9}
  For any function $l: \R^{n} \times \R^{m} \rightarrow \overline \R$
  we say that $(x', y')$ is a \textbf{saddle point} of $l$ if $l(x,
  y') \geq l(x', y') \geq l(x', y)$ for all $x, y$. The set of all
  saddle points is denoted by $\sp l$.  

  Evquivalently, $(x', y') \in \sp l$ if $\inf_{x} l(x, y') = l(x',
  y') = \sup_{y} l(x', y)$.
\end{defn}

\begin{thm}
  \label{sec:duality-optimization-10}
  Assume $f$is proper, lsc, and convex with associated Lagrangian $l$.
  Then $\phi(x) = \sup_{y} l(x, y)$, and $\psi(y) = \inf_{x} l(x, y)$,
  and the primal problem is $\inf_{x} \phi(x) = \inf_{x} \sup_{y} l(x,
  y)$, and the dual problem is $\sup_{y} \psi(y) = \sup_{y} \inf_{x}
  l(x, y)$.  Moreove, the optimality condition
  \begin{align}
    \label{eq:49}
    \{ x' \in \argmin_{x} \phi(x), y' \in \argmax_{y} \psi(y),
    \inf_{x} \phi(x) = \sup_{y} \psi(y) \}  \iff (x', y') \in \sp l
    \iff \{ 0 \in \partial_{x} l(x', y'), 0 \in \partial_{y}(-l)(x', y') \} 
  \end{align}
\end{thm}

\begin{thm}
  \label{sec:duality-optimization-11}
  Assume $X \subseteq \R^{n}$, $Y \subseteq \R^{m}$ are nonempty,
  closed, convex, and $L: X \times Y \rightarrow \R$ is a continuous
  function with $L(\cdot, y)$ is convex for every $y$ and $-L(x,
  \cdot)$ convex for every $x$.  Then $l(x, y) = L(x, y) +
  \delta_{X}(x) - \delta_{Y}(y)$ with the convention $+\infty - \infty
  = +\infty$ on the right, is the Lagrangian to $f(x, u) = \sup_{y}
  l(x, y) + \IP{u, y} = (-l(x, \cdot))^{\star}(u)$.

  $f$ is proper, lsc, and convex, so the previous result applies with
  promal and dual problems $\phi(x) = \delta_{X}(x) + \sup_{y \in Y}
  L(x, y)$, $\psi(y) = -\delta_{Y}(y) + \int_{x \in X} L(x, y)$.
  Moreover, if $X$ and $Y$ are bounded, then $\sp l$ is nonempty and bounded.
\end{thm}

\section{Numerical Optimality}
\label{sec:numerical-optimality}

\begin{defn}
  \label{sec:numerical-optimality-1}
  For $\phi: \R^{n} \rightarrow \overline \R$, a point $x$ is an
  $\epsilon$-optimal solution if $\phi(x) - \inf \phi \leq \epsilon$.
\end{defn}

\begin{defn}
  \label{sec:numerical-optimality-2}
  Assume $(x^{k}, y^{k})$ is a primal-dual feasible pair - so $x^{k}
  \in \dom \phi$ and $y^{k} \in \dom \psi$.  Then $\phi(x^{k}) \geq
  \psi(y^{k})$, and $0 \leq \phi(x^{k}) - \inf \phi \leq \phi(x^{k}) -
  \psi^{y^{k}} = \gamma(x^{k}, y^{k}) := \gamma$.  $\gamma$ is the
  \textbf{numerical primal-dual gap}.  If $\gamma < \epsilon$ then
  $x^{k}$ is an $\epsilon$-optimal solution with \textbf{optimality
    certificate} $y^{k}$.

  The normalized gap is $\overline \gamma = \overline \gamma(x^{k},
  y^{k}) = \frac{\phi(x^{k}) - \psi(y^{k})}{\psi(y^{k})}$.
\end{defn}

\begin{defn}
  \label{sec:numerical-optimality-3}
  Assume $\phi(x) = \phi_{0}(x) = \sum_{i=1}^{n_{p}} \delta_{g_{i}(x)
    \leq 0}$, $\psi(y) = \psi_{0}(y) - \sum_{i=1}^{n_{d}}
  \delta_{h_{i}(x) \leq 0}$ where $\dom \phi_{0} = \dom \psi_{0} =
  \R^{n}$ and $g_{i}: \R^{n} \rightarrow \R$, $h_{i}: \R^{m}
  \rightarrow \R$ are suitable continuous real-valued convex
  functions, so the primal and dual constraints are of the form
  $g_{i}(x) \leq 0, h_{i}(y) \leq 0$. Then the primal and dual
  infeasibilities are defined as $\eta_{p} = \max \{ 0, g_{1}(x^{k}),
  \dots, g_{n_{p}}(x^{k}) \} $ and $\eta_{d} = \max \{ 0,
  h_{1}(y^{k}), \dots, h_{n_{d}}(y^{k}) \} $.
\end{defn}

\section{First-Order Methods}
\label{sec:first-order-methods}

\begin{defn}
  \label{sec:first-order-methods-1}
  For $f: \R^{n} \rightarrow \overline \R$, we define
  \begin{enumerate}
  \item The \textbf{forward step}, $F_{\tau_{k} f}(x^{k}) = (I -
    \tau_{k} \partial f) x^{k}$
  \item The \textbf{backward step}, $B_{\tau_{k}f}(x^{k}) = (I +
    \tau_{k} \partial f)^{-1} x^{k}$.
  \end{enumerate}
\end{defn}

\begin{thm}
  \label{sec:first-order-methods-2}
  If $f: \R^{n} \rightarrow \overline \R$ is proper lsc convex with
  $\tau > 0$, then the backward step is $B_{\tau f}(x) = \argmin_{y}
  \{ \frac{1}{2} \| y - x \|_{2}^{2} + \tau f(y) \} $ and is therefore unique.
\end{thm}

\begin{thm}
  \label{sec:first-order-methods-3}
  Assume $f$ is proper lsc convex and $\argmin f \neq \emptyset$. The
  \textbf{forward step} is $x^{k+1} \in F_{\tau_{k} f}(x^{k})$. The
  sequence is not unique, can get stuck if $x^{k}$ is infeasible.

  The \textbf{backward step} is $x^{k+1} = B_{\tau_{k} f}(x^{k})$ -
  which is a \textbf{unique} sequence, and cannot get stuck.  Substeps
  are as hard as the original problem (but strictly convex).
\end{thm}

TODO - primal-dual methods, etc?

\section{Interior-Point Methods}
\label{sec:inter-point-meth}

\begin{defn}
  \label{sec:inter-point-meth-1}
  For a cone $K$ we define the \textbf{canonical barriers} $F = F_{K}$
  and associated parameters $\theta_{F}$.
  \begin{enumerate}
  \item $K = K^{LP}_{n} = \{ x \in \R^{n} | x_{1}, \dots, x_{n} \geq 0
    \} $, $F(x) = \sum_{i=1}^{n} -\log x_{i}$, $\theta_{F} = n$.
  \item $K = K_{n}^{SOCP} = \{ x \in \R^{n} | x_{n} \geq
    \sqrt{x_{1}^{2} + \cdots + x_{n-1}^{2}}\}$, $F(x) =
    -\log(x_{n}^{2} - x_{1}^{2} - \dots - x_{n-1}^{2})$, $\theta_{F} =
    2$.
  \item $K = K_{n}^{SDP} = \{ X \in \R^{n \times n} | \text{$X$
      symmetric positive semidefinite} \}$, $F(x) = - \log \det X$,
    $\theta_{F} = n$.
  \item $K = K^{1} \times K^{2}$, then $F_{K}(x^{1}, x^{2}) =
    F_{K^{1}}(x^{1}) + F_{K^{2}}(x^{2})$, with $\theta_{F} =
    \theta_{F^{1}} + \theta_{F^{2}}$.
  \end{enumerate}
\end{defn}

\begin{thm}
  \label{sec:inter-point-meth-2}
  If $F$ is a canonical barrier for $K$, then $F$ is smooth on $\dom F
  = \int K$ and strictly convex, $F(tx) = F(x) - \theta_{F} \log t$
  for all  $x \in \dom F$, and for $x \in \dom F$, we have
  \begin{enumerate}
  \item $- \grad F(x) \in \dom F$
  \item $\IP{\grad F(x), x} = - \theta_{F}$,
  \item $-\grad F(-\grad F(x)) = x$,
  \item $-\grad F(tx) = -\frac{1}{t} \grad F(x)$
  \end{enumerate}
\end{thm}

\begin{thm}
  \label{sec:inter-point-meth-3}
  The \textbf{primal central path} is the mapping $t \mapsto x(t) =
  \argmin \{ -t \IP{b, y} + F(y) + \delta_{A^{T}y = c} \} $

  The \textbf{dual central path} is the mapping $t \mapsto y(t) =
  \argmin \{ -t \IP{b, y} + F(y) + \delta_{A^{T}y = c} \} $

  The \textbf{primal-dual central path} is the mapping $t \mapsto z(t)
  = (x(t), y(t))$ for some $t > 0$, if and only if
  \begin{align}
    \label{eq:52}
    Ax - b \in \dom F \\
    \label{eq:53}
    A^{T} y = c \\
    \label{eq:54}
    ty + \grad F(Ax - b) = 0
  \end{align}
\end{thm}

\begin{thm}
  \label{sec:inter-point-meth-4}
  For feasible $x, y$ (so $Ax - b \in K$, $A^{T}y = c$, $y \in K$),
  the duality gap is $\phi(x) - \psi(y) = \IP{y, Ax - b}$.  Moreover,
  for points $(x(t), y(t))$ on the central path, the duality gap is
  $\phi(x(t)) - \psi(y(t)) = \frac{\theta_{F}}{t}$.
\end{thm}

\begin{thm}
  \label{sec:inter-point-meth-5}
  We define $\| v \|_{x}^{\star} = (v^{T} \grad^{2} F(Ax - b)^{-1}
  v)^{\frac{1}{2}}$, $z = (x, y)$, so $z(t)$ is the primal-dual
  central path, and $\dist(z, z(t)) = \| ty + \grad F(Ax -
  b)\|_{x}^{\star}$.
  Then for $Ax - b \in \dom F$, $y \in \dom F$, $A^{T}y = c$, we have
  $\dist(z, z(t)) \leq 1$ implies $\phi(x) - \psi(y) \leq 2(\phi(x(t))
  - \psi(y(t))) = 2 \frac{\theta_{F}}{t}$.
\end{thm}

\begin{thm}
  \label{sec:inter-point-meth-6}
  Assume $0 < \rho \leq \kappa < \frac{1}{10}$, $t^{k} > 0$ fixed, and
  $z^{k} = (x^{k}, y^{k})$ stirctly feasible, so $Ax^{k} - b \in \dom
  F$, $y^{k} \in \dom f$, such that $\dist(z^{k}, z(t^{k})) < \kappa$.

  If we apply a full Netwton step with $\tau_{k} = 1$ and $t^{k+1} = (1
  + \frac{\rho}{\sqrt{\theta_{F}}}) t^{k}$ to generate $z^{k+1}$, then
  $x^{k+1}, y^{k+1}$ are strictly primal and dual feasible, and
  $\dist(z^{k+1}, z(t^{k+1})) > \kappa$ as well.
\end{thm}

\section{Support Vector Machines}
\label{sec:supp-vect-mach}

\begin{defn}
  \label{sec:supp-vect-mach-1}
  The primal formulation of an SVM is
  \begin{align}
    \label{eq:18}
    \inf_{w, b} \frac{1}{2} \| w \|_{2}^{2}
  \end{align} such that $1 \leq y^{i} (\IP{w, x^{i}} + b)$ for all $1
  \leq i \leq n$.

  The dual formulation is
  \begin{align}
    \label{eq:48}
    \inf_{z \in \R^{n}} \frac{1}{2} \| \sum_{i=1}^{n} y^{i} x^{i}
    z_{i} \|_{2}^{2} + e^{T} z
  \end{align} such that $z_{i} \leq 0$, $\sum_{i=1}^{n} y^{i} z_{i} = 0$.
\end{defn}

\section{Total Variation and Applications}
\label{sec:total-vari-appl}

\begin{defn}
  \label{sec:total-vari-appl-1}
  For $u \in L^{1}(\Omega, \R^{m})$, the \textbf{total variation} of
  $u$ is defined as
  \begin{equation}
    \label{eq:50}
    TV(u)= \sup_{v \in C_{c}^{1}(\Omega, \R^{m \times n}), \| v
      \|_{\infty} \leq 1} \int_{\Omega} \IP{u, \divergence v} dx
  \end{equation}
\end{defn}

\begin{thm}
  \label{sec:total-vari-appl-2}
  Assume $A \subseteq \Omega$ is a set so that its boundary is $C^{1}$
  and satisfies $\mathcal{H}^{n-1}(\Omega \cap \partial A) < \infty$.
  Define
  \begin{equation}
    \label{eq:51}
    \I{A}(x) =
    \begin{cases}
      1 & x \in A \\
      0 & x \notin A
    \end{cases}
  \end{equation}
  then $TV(\I{A}) = \mathcal{H}^{n-1}(\Omega \cap \partial A)$.
\end{thm}

\begin{thm}
  \label{sec:total-vari-appl-3}
  If $u \in BV(\Omega)$, then $TV(\I{x|u(x) > t}) < \infty$ for
  $\mathcal{L}^{1}$-a.e. $t \in \R$, and $TV(u) = \int_{\R} TV(\I{u >
    t}) dt$.
\end{thm}

\begin{defn}
  \label{sec:total-vari-appl-4}
  For $\Omega \subseteq \R^{d}$ and $k \geq 1$, define the space
  $BV^{k}(\Omega)$ as $BV^{k} = \{ u \in W^{k-1, 1} | \grad^{k-1}u \in
BV(\Omega, R^{d^{k-1}}) \}$ and the higer-ordre total variation as
\begin{align}
  \label{eq:56}
  TV^{k}(u) = \sup_{v \in C_{c}^{k}(\Omega, \sym^{k}(\R^{d})), \| v
    \|_{\infty} \leq 1} \int_{\Omega} u \divergence^{k} v dx = TV(\grad^{k-1}
  u)
\end{align}
\end{defn}

\todo{Fill in all the total variation stuff?}

\bibliographystyle{plainnat}
\bibliography{../../common/bibliography}
\end{document}